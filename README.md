# An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
Neste blog, mergulhamos no artigo ICLR 2019 Reward Constrained Policy Optimization (RCPO) de Tessler et al. e destacamos a importância da modelagem adaptativa de recompensas no aprendizado por reforço seguro. Reproduzimos os resultados experimentais do artigo implementando o RCPO na Otimização de Políticas Proximais (PPO). Este blog tem como objetivo fornecer aos pesquisadores e profissionais (1) uma melhor compreensão do aprendizado por reforço seguro em termos de otimização restrita e (2) como as funções de recompensa penalizadas podem ser efetivamente usadas para treinar uma política robusta
![image](https://github.com/user-attachments/assets/f87cb646-8a58-4dd5-b814-b1eee75b0ddc)

